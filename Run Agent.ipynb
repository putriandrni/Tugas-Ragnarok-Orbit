{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0a72dc7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Importing classes\n",
    "from env import Environment\n",
    "from agent_brain import QLearningTable\n",
    "\n",
    "def update():\n",
    "    # Resulted list for the plotting Episodes via Steps\n",
    "    steps = []\n",
    "\n",
    "    # Summed costs for all episodes in resulted list\n",
    "    all_costs = []\n",
    "\n",
    "    for episode in range(1000):\n",
    "        # Initial Observation\n",
    "        observation = env.reset()\n",
    "\n",
    "        # Updating number of Steps for each Episode\n",
    "        i = 0\n",
    "\n",
    "        # Updating the cost for each episode\n",
    "        cost = 0\n",
    "\n",
    "        while True:\n",
    "            # Refreshing environment\n",
    "            env.render()\n",
    "\n",
    "            # RL chooses action based on observation\n",
    "            action = RL.choose_action(str(observation))\n",
    "\n",
    "            # RL takes an action and get the next observation and reward\n",
    "            observation_, reward, done = env.step(action)\n",
    "\n",
    "            # RL learns from this transition and calculating the cost\n",
    "            cost += RL.learn(str(observation), action, reward, str(observation_))\n",
    "\n",
    "            # Swapping the observations - current and next\n",
    "            observation = observation_\n",
    "\n",
    "            # Calculating number of Steps in the current Episode\n",
    "            i += 1\n",
    "\n",
    "            # Break while loop when it is the end of current Episode\n",
    "            # When agent reached the goal or obstacle\n",
    "            if done:\n",
    "                steps += [i]\n",
    "                all_costs += [cost]\n",
    "                break\n",
    "\n",
    "    # Showing the final route\n",
    "    env.final()\n",
    "\n",
    "    # Showing the Q-table with values for each action\n",
    "    RL.print_q_table()\n",
    "\n",
    "    # Plotting the results\n",
    "    RL.plot_results(steps, all_costs)\n",
    "\n",
    "\n",
    "# Commands to be implemented after running this file\n",
    "if __name__ == \"__helo__\":\n",
    "    # Calling for the environment\n",
    "    env = Environment()\n",
    "    # Calling for the main algorithm\n",
    "    RL = QLearningTable(actions=list(range(env.n_actions)))\n",
    "    # Running the main loop with Episodes by calling the function update()\n",
    "    env.after(100, update)  # Or just update()\n",
    "    env.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e004332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np  # To deal with data in form of matrices\n",
    "import tkinter as tk  # To build GUI\n",
    "import time  # Time is needed to slow down the agent and to see how he runs\n",
    "from PIL import Image, ImageTk  # For adding images into the canvas widget\n",
    "\n",
    "# Setting the sizes for the environment\n",
    "pixels = 40   # pixels\n",
    "env_height = 9  # grid height\n",
    "env_width = 9  # grid width\n",
    "\n",
    "# Global variable for dictionary with coordinates for the final route\n",
    "a = {}\n",
    "\n",
    "\n",
    "# Creating class for the environment\n",
    "class Environment(tk.Tk, object):\n",
    "    def __init__(self):\n",
    "        super(Environment, self).__init__()\n",
    "        self.action_space = ['up', 'down', 'left', 'right']\n",
    "        self.n_actions = len(self.action_space)\n",
    "        self.title('RL Q-learning. Sichkar Valentyn')\n",
    "        self.geometry('{0}x{1}'.format(env_height * pixels, env_height * pixels))\n",
    "        self.build_environment()\n",
    "\n",
    "        # Dictionaries to draw the final route\n",
    "        self.d = {}\n",
    "        self.f = {}\n",
    "\n",
    "        # Key for the dictionaries\n",
    "        self.i = 0\n",
    "\n",
    "        # Writing the final dictionary first time\n",
    "        self.c = True\n",
    "\n",
    "        # Showing the steps for longest found route\n",
    "        self.longest = 0\n",
    "\n",
    "        # Showing the steps for the shortest route\n",
    "        self.shortest = 0\n",
    "\n",
    "    # Function to build the environment\n",
    "    def build_environment(self):\n",
    "        self.canvas_widget = tk.Canvas(self,  bg='white',\n",
    "                                       height=env_height * pixels,\n",
    "                                       width=env_width * pixels)\n",
    "\n",
    "        # Uploading an image for background\n",
    "        # img_background = Image.open(\"images/bg.png\")\n",
    "        # self.background = ImageTk.PhotoImage(img_background)\n",
    "        # # Creating background on the widget\n",
    "        # self.bg = self.canvas_widget.create_image(0, 0, anchor='nw', image=self.background)\n",
    "\n",
    "        # Creating grid lines\n",
    "        for column in range(0, env_width * pixels, pixels):\n",
    "            x0, y0, x1, y1 = column, 0, column, env_height * pixels\n",
    "            self.canvas_widget.create_line(x0, y0, x1, y1, fill='grey')\n",
    "        for row in range(0, env_height * pixels, pixels):\n",
    "            x0, y0, x1, y1 = 0, row, env_height * pixels, row\n",
    "            self.canvas_widget.create_line(x0, y0, x1, y1, fill='grey')\n",
    "\n",
    "        # Creating objects of  Obstacles\n",
    "        # Obstacle type 1 - road closed1\n",
    "        img_obstacle1 = Image.open(\"images/road_closed1.png\")\n",
    "        self.obstacle1_object = ImageTk.PhotoImage(img_obstacle1)\n",
    "        # Obstacle type 2 - tree1\n",
    "        img_obstacle2 = Image.open(\"images/tree1.png\")\n",
    "        self.obstacle2_object = ImageTk.PhotoImage(img_obstacle2)\n",
    "        # Obstacle type 3 - tree2\n",
    "        img_obstacle3 = Image.open(\"images/tree2.png\")\n",
    "        self.obstacle3_object = ImageTk.PhotoImage(img_obstacle3)\n",
    "        # Obstacle type 4 - building1\n",
    "        img_obstacle4 = Image.open(\"images/building1.png\")\n",
    "        self.obstacle4_object = ImageTk.PhotoImage(img_obstacle4)\n",
    "        # Obstacle type 5 - building2\n",
    "        img_obstacle5 = Image.open(\"images/building2.png\")\n",
    "        self.obstacle5_object = ImageTk.PhotoImage(img_obstacle5)\n",
    "        # Obstacle type 6 - road closed2\n",
    "        img_obstacle6 = Image.open(\"images/road_closed2.png\")\n",
    "        self.obstacle6_object = ImageTk.PhotoImage(img_obstacle6)\n",
    "        # Obstacle type 7 - road closed3\n",
    "        img_obstacle7 = Image.open(\"images/road_closed3.png\")\n",
    "        self.obstacle7_object = ImageTk.PhotoImage(img_obstacle7)\n",
    "        # Obstacle type 8 - traffic lights\n",
    "        img_obstacle8 = Image.open(\"images/traffic_lights.png\")\n",
    "        self.obstacle8_object = ImageTk.PhotoImage(img_obstacle8)\n",
    "        # Obstacle type 9 - pedestrian\n",
    "        img_obstacle9 = Image.open(\"images/pedestrian.png\")\n",
    "        self.obstacle9_object = ImageTk.PhotoImage(img_obstacle9)\n",
    "        # Obstacle type 10 - shop\n",
    "        img_obstacle10 = Image.open(\"images/shop.png\")\n",
    "        self.obstacle10_object = ImageTk.PhotoImage(img_obstacle10)\n",
    "        # Obstacle type 11 - bank1\n",
    "        img_obstacle11 = Image.open(\"images/bank1.png\")\n",
    "        self.obstacle11_object = ImageTk.PhotoImage(img_obstacle11)\n",
    "        # Obstacle type 12 - bank2\n",
    "        img_obstacle12 = Image.open(\"images/bank2.png\")\n",
    "        self.obstacle12_object = ImageTk.PhotoImage(img_obstacle12)\n",
    "\n",
    "        # Creating obstacles themselves\n",
    "        # Obstacles from 1 to 22\n",
    "        self.obstacle1 = self.canvas_widget.create_image(pixels * 3, pixels * 4, anchor='nw', image=self.obstacle2_object)\n",
    "        # Obstacle 2\n",
    "        self.obstacle2 = self.canvas_widget.create_image(0, pixels * 2, anchor='nw', image=self.obstacle6_object)\n",
    "        # Obstacle 3\n",
    "        self.obstacle3 = self.canvas_widget.create_image(pixels, 0, anchor='nw', image=self.obstacle5_object)\n",
    "        # Obstacle 4\n",
    "        self.obstacle4 = self.canvas_widget.create_image(pixels * 3, pixels * 2, anchor='nw', image=self.obstacle2_object)\n",
    "        # Obstacle 5\n",
    "        self.obstacle5 = self.canvas_widget.create_image(pixels * 4, 0, anchor='nw', image=self.obstacle12_object)\n",
    "        # Obstacle 6\n",
    "        self.obstacle6 = self.canvas_widget.create_image(pixels * 5, pixels * 3, anchor='nw', image=self.obstacle7_object)\n",
    "        # Obstacle 7\n",
    "        self.obstacle7 = self.canvas_widget.create_image(pixels * 7, pixels * 3, anchor='nw', image=self.obstacle9_object)\n",
    "        # Obstacle 8\n",
    "        self.obstacle8 = self.canvas_widget.create_image(pixels * 6, pixels, anchor='nw', image=self.obstacle10_object)\n",
    "        # Obstacle 9\n",
    "        self.obstacle9 = self.canvas_widget.create_image(pixels * 5, pixels * 5, anchor='nw', image=self.obstacle4_object)\n",
    "        # Obstacle 10\n",
    "        self.obstacle10 = self.canvas_widget.create_image(pixels * 6, pixels * 5, anchor='nw', image=self.obstacle4_object)\n",
    "        # Obstacle 11\n",
    "        self.obstacle11 = self.canvas_widget.create_image(pixels * 5, pixels * 6, anchor='nw', image=self.obstacle4_object)\n",
    "        # Obstacle 12\n",
    "        self.obstacle12 = self.canvas_widget.create_image(pixels * 5, pixels * 7, anchor='nw', image=self.obstacle4_object)\n",
    "        # Obstacle 13\n",
    "        self.obstacle13 = self.canvas_widget.create_image(0, pixels * 8, anchor='nw', image=self.obstacle3_object)\n",
    "        # Obstacle 14\n",
    "        self.obstacle14 = self.canvas_widget.create_image(pixels * 3, pixels * 7, anchor='nw', image=self.obstacle8_object)\n",
    "        # Obstacle 15\n",
    "        self.obstacle15 = self.canvas_widget.create_image(0, pixels * 4, anchor='nw', image=self.obstacle1_object)\n",
    "        # Obstacle 16\n",
    "        self.obstacle16 = self.canvas_widget.create_image(pixels * 8, 0, anchor='nw', image=self.obstacle3_object)\n",
    "        # Obstacle 17\n",
    "        self.obstacle17 = self.canvas_widget.create_image(pixels * 7, pixels * 7, anchor='nw', image=self.obstacle4_object)\n",
    "        # Obstacle 18\n",
    "        self.obstacle18 = self.canvas_widget.create_image(pixels, pixels * 6, anchor='nw', image=self.obstacle11_object)\n",
    "        # Obstacle 19\n",
    "        self.obstacle19 = self.canvas_widget.create_image(pixels * 8, pixels * 3, anchor='nw', image=self.obstacle8_object)\n",
    "        # Obstacle 20\n",
    "        self.obstacle20 = self.canvas_widget.create_image(pixels * 7, pixels * 6, anchor='nw', image=self.obstacle4_object)\n",
    "        # Obstacle 21\n",
    "        self.obstacle21 = self.canvas_widget.create_image(pixels * 7, pixels * 5, anchor='nw', image=self.obstacle4_object)\n",
    "        # Obstacle 22\n",
    "        self.obstacle22 = self.canvas_widget.create_image(pixels * 2, pixels * 3, anchor='nw', image=self.obstacle2_object)\n",
    "\n",
    "        # Final Point\n",
    "        img_flag = Image.open(\"images/flag.png\")\n",
    "        self.flag_object = ImageTk.PhotoImage(img_flag)\n",
    "        self.flag = self.canvas_widget.create_image(pixels * 6, pixels * 6, anchor='nw', image=self.flag_object)\n",
    "\n",
    "        # Uploading the image of Mobile Robot\n",
    "        img_robot = Image.open(\"images/agent1.png\")\n",
    "        self.robot = ImageTk.PhotoImage(img_robot)\n",
    "\n",
    "        # Creating an agent with photo of Mobile Robot\n",
    "        self.agent = self.canvas_widget.create_image(0, 0, anchor='nw', image=self.robot)\n",
    "\n",
    "        # Packing everything\n",
    "        self.canvas_widget.pack()\n",
    "\n",
    "    # Function to reset the environment and start new Episode\n",
    "    def reset(self):\n",
    "        self.update()\n",
    "        #time.sleep(0.1)\n",
    "\n",
    "        # Updating agent\n",
    "        self.canvas_widget.delete(self.agent)\n",
    "        self.agent = self.canvas_widget.create_image(0, 0, anchor='nw', image=self.robot)\n",
    "\n",
    "        # # Clearing the dictionary and the i\n",
    "        self.d = {}\n",
    "        self.i = 0\n",
    "\n",
    "        # Return observation\n",
    "        return self.canvas_widget.coords(self.agent)\n",
    "\n",
    "    # Function to get the next observation and reward by doing next step\n",
    "    def step(self, action):\n",
    "        # Current state of the agent\n",
    "        state = self.canvas_widget.coords(self.agent)\n",
    "        base_action = np.array([0, 0])\n",
    "\n",
    "        # Updating next state according to the action\n",
    "        # Action 'up'\n",
    "        if action == 0:\n",
    "            if state[1] >= pixels:\n",
    "                base_action[1] -= pixels\n",
    "        # Action 'down'\n",
    "        elif action == 1:\n",
    "            if state[1] < (env_height - 1) * pixels:\n",
    "                base_action[1] += pixels\n",
    "        # Action right\n",
    "        elif action == 2:\n",
    "            if state[0] < (env_width - 1) * pixels:\n",
    "                base_action[0] += pixels\n",
    "        # Action left\n",
    "        elif action == 3:\n",
    "            if state[0] >= pixels:\n",
    "                base_action[0] -= pixels\n",
    "\n",
    "        # Moving the agent according to the action\n",
    "        self.canvas_widget.move(self.agent, base_action[0], base_action[1])\n",
    "\n",
    "        # Writing in the dictionary coordinates of found route\n",
    "        self.d[self.i] = self.canvas_widget.coords(self.agent)\n",
    "\n",
    "        # Updating next state\n",
    "        next_state = self.d[self.i]\n",
    "\n",
    "        # Updating key for the dictionary\n",
    "        self.i += 1\n",
    "\n",
    "        # Calculating the reward for the agent\n",
    "        if next_state == self.canvas_widget.coords(self.flag):\n",
    "            reward = 1\n",
    "            done = True\n",
    "            next_state = 'goal'\n",
    "\n",
    "            # Filling the dictionary first time\n",
    "            if self.c == True:\n",
    "                for j in range(len(self.d)):\n",
    "                    self.f[j] = self.d[j]\n",
    "                self.c = False\n",
    "                self.longest = len(self.d)\n",
    "                self.shortest = len(self.d)\n",
    "\n",
    "            # Checking if the currently found route is shorter\n",
    "            if len(self.d) < len(self.f):\n",
    "                # Saving the number of steps for the shortest route\n",
    "                self.shortest = len(self.d)\n",
    "                # Clearing the dictionary for the final route\n",
    "                self.f = {}\n",
    "                # Reassigning the dictionary\n",
    "                for j in range(len(self.d)):\n",
    "                    self.f[j] = self.d[j]\n",
    "\n",
    "            # Saving the number of steps for the longest route\n",
    "            if len(self.d) > self.longest:\n",
    "                self.longest = len(self.d)\n",
    "\n",
    "        elif next_state in [self.canvas_widget.coords(self.obstacle1),\n",
    "                            self.canvas_widget.coords(self.obstacle2),\n",
    "                            self.canvas_widget.coords(self.obstacle3),\n",
    "                            self.canvas_widget.coords(self.obstacle4),\n",
    "                            self.canvas_widget.coords(self.obstacle5),\n",
    "                            self.canvas_widget.coords(self.obstacle6),\n",
    "                            self.canvas_widget.coords(self.obstacle7),\n",
    "                            self.canvas_widget.coords(self.obstacle8),\n",
    "                            self.canvas_widget.coords(self.obstacle9),\n",
    "                            self.canvas_widget.coords(self.obstacle10),\n",
    "                            self.canvas_widget.coords(self.obstacle11),\n",
    "                            self.canvas_widget.coords(self.obstacle12),\n",
    "                            self.canvas_widget.coords(self.obstacle13),\n",
    "                            self.canvas_widget.coords(self.obstacle14),\n",
    "                            self.canvas_widget.coords(self.obstacle15),\n",
    "                            self.canvas_widget.coords(self.obstacle16),\n",
    "                            self.canvas_widget.coords(self.obstacle17),\n",
    "                            self.canvas_widget.coords(self.obstacle18),\n",
    "                            self.canvas_widget.coords(self.obstacle19),\n",
    "                            self.canvas_widget.coords(self.obstacle20),\n",
    "                            self.canvas_widget.coords(self.obstacle21),\n",
    "                            self.canvas_widget.coords(self.obstacle22)]:\n",
    "            reward = -1\n",
    "            done = True\n",
    "            next_state = 'obstacle'\n",
    "\n",
    "            # Clearing the dictionary and the i\n",
    "            self.d = {}\n",
    "            self.i = 0\n",
    "\n",
    "        else:\n",
    "            reward = 0\n",
    "            done = False\n",
    "\n",
    "        return next_state, reward, done\n",
    "\n",
    "    # Function to refresh the environment\n",
    "    def render(self):\n",
    "        #time.sleep(0.03)\n",
    "        self.update()\n",
    "\n",
    "    # Function to show the found route\n",
    "    def final(self):\n",
    "        # Deleting the agent at the end\n",
    "        self.canvas_widget.delete(self.agent)\n",
    "\n",
    "        # Showing the number of steps\n",
    "        print('The shortest route:', self.shortest)\n",
    "        print('The longest route:', self.longest)\n",
    "\n",
    "        # Creating initial point\n",
    "        origin = np.array([20, 20])\n",
    "        self.initial_point = self.canvas_widget.create_oval(\n",
    "            origin[0] - 5, origin[1] - 5,\n",
    "            origin[0] + 5, origin[1] + 5,\n",
    "            fill='blue', outline='blue')\n",
    "\n",
    "        # Filling the route\n",
    "        for j in range(len(self.f)):\n",
    "            # Showing the coordinates of the final route\n",
    "            print(self.f[j])\n",
    "            self.track = self.canvas_widget.create_oval(\n",
    "                self.f[j][0] + origin[0] - 5, self.f[j][1] + origin[0] - 5,\n",
    "                self.f[j][0] + origin[0] + 5, self.f[j][1] + origin[0] + 5,\n",
    "                fill='blue', outline='blue')\n",
    "            # Writing the final route in the global variable a\n",
    "            a[j] = self.f[j]\n",
    "\n",
    "\n",
    "# Returning the final dictionary with route coordinates\n",
    "# Then it will be used in agent_brain.py\n",
    "def final_states():\n",
    "    return a\n",
    "\n",
    "\n",
    "# This we need to debug the environment\n",
    "# If we want to run and see the environment without running full algorithm\n",
    "if __name__ == '__helo__':\n",
    "    env = Environment()\n",
    "    env.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45bbaec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Importing function from the env.py\n",
    "from env import final_states\n",
    "\n",
    "\n",
    "# Creating class for the Q-learning table\n",
    "class QLearningTable:\n",
    "    def __init__(self, actions, learning_rate=0.01, reward_decay=0.9, e_greedy=0.9):\n",
    "        # List of actions\n",
    "        self.actions = actions\n",
    "        # Learning rate\n",
    "        self.lr = learning_rate\n",
    "        # Value of gamma\n",
    "        self.gamma = reward_decay\n",
    "        # Value of epsilon\n",
    "        self.epsilon = e_greedy\n",
    "        # Creating full Q-table for all cells\n",
    "        self.q_table = pd.DataFrame(columns=self.actions, dtype=np.float64)\n",
    "        # Creating Q-table for cells of the final route\n",
    "        self.q_table_final = pd.DataFrame(columns=self.actions, dtype=np.float64)\n",
    "\n",
    "    # Function for choosing the action for the agent\n",
    "    def choose_action(self, observation):\n",
    "        # Checking if the state exists in the table\n",
    "        self.check_state_exist(observation)\n",
    "        # Selection of the action - 90 % according to the epsilon == 0.9\n",
    "        # Choosing the best action\n",
    "        if np.random.uniform() < self.epsilon:\n",
    "            state_action = self.q_table.loc[observation, :]\n",
    "            state_action = state_action.reindex(np.random.permutation(state_action.index))\n",
    "            action = state_action.idxmax()\n",
    "        else:\n",
    "            # Choosing random action - left 10 % for choosing randomly\n",
    "            action = np.random.choice(self.actions)\n",
    "        return action\n",
    "\n",
    "    # Function for learning and updating Q-table with new knowledge\n",
    "    def learn(self, state, action, reward, next_state):\n",
    "        # Checking if the next step exists in the Q-table\n",
    "        self.check_state_exist(next_state)\n",
    "\n",
    "        # Current state in the current position\n",
    "        q_predict = self.q_table.loc[state, action]\n",
    "\n",
    "        # Checking if the next state is free or it is obstacle or goal\n",
    "        if next_state != 'goal' or next_state != 'obstacle':\n",
    "            q_target = reward + self.gamma * self.q_table.loc[next_state, :].max()\n",
    "        else:\n",
    "            q_target = reward\n",
    "\n",
    "        # Updating Q-table with new knowledge\n",
    "        self.q_table.loc[state, action] += self.lr * (q_target - q_predict)\n",
    "\n",
    "        return self.q_table.loc[state, action]\n",
    "\n",
    "    # Adding to the Q-table new states\n",
    "    def check_state_exist(self, state):\n",
    "        if state not in self.q_table.index:\n",
    "            self.q_table = self.q_table.append(\n",
    "                pd.Series(\n",
    "                    [0]*len(self.actions),\n",
    "                    index=self.q_table.columns,\n",
    "                    name=state,\n",
    "                )\n",
    "            )\n",
    "\n",
    "    # Printing the Q-table with states\n",
    "    def print_q_table(self):\n",
    "        # Getting the coordinates of final route from env.py\n",
    "        e = final_states()\n",
    "\n",
    "        # Comparing the indexes with coordinates and writing in the new Q-table values\n",
    "        for i in range(len(e)):\n",
    "            state = str(e[i])  # state = '[5.0, 40.0]'\n",
    "            # Going through all indexes and checking\n",
    "            for j in range(len(self.q_table.index)):\n",
    "                if self.q_table.index[j] == state:\n",
    "                    self.q_table_final.loc[state, :] = self.q_table.loc[state, :]\n",
    "\n",
    "        print()\n",
    "        print('Length of final Q-table =', len(self.q_table_final.index))\n",
    "        print('Final Q-table with values from the final route:')\n",
    "        print(self.q_table_final)\n",
    "\n",
    "        print()\n",
    "        print('Length of full Q-table =', len(self.q_table.index))\n",
    "        print('Full Q-table:')\n",
    "        print(self.q_table)\n",
    "\n",
    "    # Plotting the results for the number of steps\n",
    "    def plot_results(self, steps, cost):\n",
    "        #\n",
    "        f, (ax1, ax2) = plt.subplots(nrows=1, ncols=2)\n",
    "        #\n",
    "        ax1.plot(np.arange(len(steps)), steps, 'b')\n",
    "        ax1.set_xlabel('Episode')\n",
    "        ax1.set_ylabel('Steps')\n",
    "        ax1.set_title('Episode via steps')\n",
    "\n",
    "        #\n",
    "        ax2.plot(np.arange(len(cost)), cost, 'r')\n",
    "        ax2.set_xlabel('Episode')\n",
    "        ax2.set_ylabel('Cost')\n",
    "        ax2.set_title('Episode via cost')\n",
    "\n",
    "        plt.tight_layout()  # Function to make distance between figures\n",
    "\n",
    "        #\n",
    "        plt.figure()\n",
    "        plt.plot(np.arange(len(steps)), steps, 'b')\n",
    "        plt.title('Episode via steps')\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Steps')\n",
    "\n",
    "        #\n",
    "        plt.figure()\n",
    "        plt.plot(np.arange(len(cost)), cost, 'r')\n",
    "        plt.title('Episode via cost')\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Cost')\n",
    "\n",
    "        # Showing the plots\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4651f741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ALLUSERSPROFILE': 'C:\\\\ProgramData',\n",
       " 'APPDATA': 'C:\\\\Users\\\\Putri\\\\AppData\\\\Roaming',\n",
       " 'COMMONPROGRAMFILES': 'C:\\\\Program Files\\\\Common Files',\n",
       " 'COMMONPROGRAMFILES(X86)': 'C:\\\\Program Files (x86)\\\\Common Files',\n",
       " 'COMMONPROGRAMW6432': 'C:\\\\Program Files\\\\Common Files',\n",
       " 'COMPUTERNAME': 'LAPTOP-R5AONFVR',\n",
       " 'COMSPEC': 'C:\\\\WINDOWS\\\\system32\\\\cmd.exe',\n",
       " 'CONDA_DEFAULT_ENV': 'base',\n",
       " 'CONDA_EXE': 'C:\\\\Users\\\\Putri\\\\anaconda3\\\\Scripts\\\\conda.exe',\n",
       " 'CONDA_PROMPT_MODIFIER': '(base) ',\n",
       " 'CONDA_PYTHON_EXE': 'C:\\\\Users\\\\Putri\\\\anaconda3\\\\python.exe',\n",
       " 'CONDA_ROOT': 'C:\\\\Users\\\\Putri\\\\anaconda3',\n",
       " 'CONDA_SHLVL': '1',\n",
       " 'DRIVERDATA': 'C:\\\\Windows\\\\System32\\\\Drivers\\\\DriverData',\n",
       " 'FPS_BROWSER_APP_PROFILE_STRING': 'Internet Explorer',\n",
       " 'FPS_BROWSER_USER_PROFILE_STRING': 'Default',\n",
       " 'HOMEDRIVE': 'C:',\n",
       " 'HOMEPATH': '\\\\Users\\\\Putri',\n",
       " 'LOCALAPPDATA': 'C:\\\\Users\\\\Putri\\\\AppData\\\\Local',\n",
       " 'LOGONSERVER': '\\\\\\\\LAPTOP-R5AONFVR',\n",
       " 'NUMBER_OF_PROCESSORS': '8',\n",
       " 'ONEDRIVE': 'C:\\\\Users\\\\Putri\\\\OneDrive',\n",
       " 'ONEDRIVECONSUMER': 'C:\\\\Users\\\\Putri\\\\OneDrive',\n",
       " 'OS': 'Windows_NT',\n",
       " 'PATH': 'C:\\\\Users\\\\Putri\\\\anaconda3;C:\\\\Users\\\\Putri\\\\anaconda3\\\\Library\\\\mingw-w64\\\\bin;C:\\\\Users\\\\Putri\\\\anaconda3\\\\Library\\\\usr\\\\bin;C:\\\\Users\\\\Putri\\\\anaconda3\\\\Library\\\\bin;C:\\\\Users\\\\Putri\\\\anaconda3\\\\Scripts;C:\\\\Users\\\\Putri\\\\anaconda3\\\\bin;C:\\\\Users\\\\Putri\\\\anaconda3\\\\condabin;C:\\\\Users\\\\Putri\\\\anaconda3;C:\\\\Users\\\\Putri\\\\anaconda3\\\\Library\\\\mingw-w64\\\\bin;C:\\\\Users\\\\Putri\\\\anaconda3\\\\Library\\\\usr\\\\bin;C:\\\\Users\\\\Putri\\\\anaconda3\\\\Library\\\\bin;C:\\\\Users\\\\Putri\\\\anaconda3\\\\Scripts;C:\\\\Program Files\\\\Python310\\\\Scripts;C:\\\\Program Files\\\\Python310;C:\\\\Program Files\\\\Common Files\\\\Oracle\\\\Java\\\\javapath;C:\\\\Program Files (x86)\\\\Common Files\\\\Oracle\\\\Java\\\\javapath;C:\\\\Program Files\\\\Java\\\\jdk1.8.0_261\\\\bin;C:\\\\WINDOWS\\\\system32;C:\\\\WINDOWS;C:\\\\WINDOWS\\\\System32\\\\Wbem;C:\\\\WINDOWS\\\\System32\\\\WindowsPowerShell\\\\v1.0;C:\\\\WINDOWS\\\\System32\\\\OpenSSH;C:\\\\Program Files\\\\Git\\\\cmd;C:\\\\Users\\\\Putri\\\\anaconda3;C:\\\\Users\\\\Putri\\\\anaconda3\\\\Library\\\\mingw-w64\\\\bin;C:\\\\Users\\\\Putri\\\\anaconda3\\\\Library\\\\usr\\\\bin;C:\\\\Users\\\\Putri\\\\anaconda3\\\\Library\\\\bin;C:\\\\Users\\\\Putri\\\\anaconda3\\\\Scripts;C:\\\\Users\\\\Putri\\\\AppData\\\\Local\\\\Microsoft\\\\WindowsApps;C:\\\\Users\\\\Putri\\\\AppData\\\\Local\\\\Programs\\\\Microsoft VS Code\\\\bin;C:\\\\Users\\\\Putri\\\\AppData\\\\Local\\\\GitHubDesktop\\\\bin;C:\\\\Program Files\\\\heroku\\\\bin',\n",
       " 'PATHEXT': '.COM;.EXE;.BAT;.CMD;.VBS;.VBE;.JS;.JSE;.WSF;.WSH;.MSC;.PY;.PYW',\n",
       " 'PROCESSOR_ARCHITECTURE': 'AMD64',\n",
       " 'PROCESSOR_IDENTIFIER': 'Intel64 Family 6 Model 126 Stepping 5, GenuineIntel',\n",
       " 'PROCESSOR_LEVEL': '6',\n",
       " 'PROCESSOR_REVISION': '7e05',\n",
       " 'PROGRAMDATA': 'C:\\\\ProgramData',\n",
       " 'PROGRAMFILES': 'C:\\\\Program Files',\n",
       " 'PROGRAMFILES(X86)': 'C:\\\\Program Files (x86)',\n",
       " 'PROGRAMW6432': 'C:\\\\Program Files',\n",
       " 'PROMPT': '(base) $P$G',\n",
       " 'PSMODULEPATH': 'C:\\\\Program Files\\\\WindowsPowerShell\\\\Modules;C:\\\\WINDOWS\\\\system32\\\\WindowsPowerShell\\\\v1.0\\\\Modules',\n",
       " 'PUBLIC': 'C:\\\\Users\\\\Public',\n",
       " 'SESSIONNAME': 'Console',\n",
       " 'SYSTEMDRIVE': 'C:',\n",
       " 'SYSTEMROOT': 'C:\\\\WINDOWS',\n",
       " 'TEMP': 'C:\\\\Users\\\\Putri\\\\AppData\\\\Local\\\\Temp',\n",
       " 'TMP': 'C:\\\\Users\\\\Putri\\\\AppData\\\\Local\\\\Temp',\n",
       " 'USERDOMAIN': 'LAPTOP-R5AONFVR',\n",
       " 'USERDOMAIN_ROAMINGPROFILE': 'LAPTOP-R5AONFVR',\n",
       " 'USERNAME': 'Putri',\n",
       " 'USERPROFILE': 'C:\\\\Users\\\\Putri',\n",
       " 'VBOX_MSI_INSTALL_PATH': 'C:\\\\Program Files\\\\Oracle\\\\VirtualBox\\\\',\n",
       " 'WINDIR': 'C:\\\\WINDOWS',\n",
       " 'CONDA_PREFIX': 'C:\\\\Users\\\\Putri\\\\anaconda3',\n",
       " 'JPY_INTERRUPT_EVENT': '2356',\n",
       " 'IPY_INTERRUPT_EVENT': '2356',\n",
       " 'JPY_PARENT_PID': '1496',\n",
       " 'TERM': 'xterm-color',\n",
       " 'CLICOLOR': '1',\n",
       " 'PAGER': 'cat',\n",
       " 'GIT_PAGER': 'cat',\n",
       " 'MPLBACKEND': 'module://ipykernel.pylab.backend_inline'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9f1cf8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b416cf29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
